

## Breaking changes

Adding a persistent storage layer changes a few design points.

### Input CLI flags the should be removed (they are now redundant).

* `--pretty_print`
	* we don't use this now as we want to be more efficient with storage in DB
* `--output_file`
	* items stored in DB, so no longer required
* `--encode_output`
	* we don't use this now as we want to be more efficient and secure with storage in DB. All entries should be decoded
* `--ignore_live_feed_entries`
    * live feed items now always included. As per old code, live entries should always take precedent
* `--latest_entry`
	* now app always requests data for time of execution

### Input CLI flags that should be moved to `.env` config settings

* `--sleep_seconds`
* `--number_of_retries`
* `--earliest_entry`

Also, the SCRAPFLY_APIKEY should be kept in `.env`

Also, page limit returned by API should be kept in `.env`

### Input CLI flags that move to API Parameters used on each request

* `--url`

## New concepts introduced

* feeds: information about the blog
* posts: the posts that belong to a feed (blog)
* jobs: what are responsible for getting the data. By wrapping requests for data in a job, user can easily track if they are successful or not.

## Feed storage

For each feed history4feed stores the following in the database;

* `id`: UUID of feed generated by history4feed
* `state`: because initial backfill may take time before record complete, feed can have two states `PENDING` (initial backfill happening), `ACTIVE` (initial posts all added)
* `url`: what user enters. This is what defines a unique feed
* `title`: found in the `<channel>` of RSS output. Is always kept up to date with the latest feed import values for this property.
* `description`: found in the `<channel>` of RSS output. Is always kept up to date with the latest feed import values for this property.
* `datetime_added`: date feed entry was added to database
* `earliest_item_pubdate`: `YYYY-MM-DD` of earliest item `pubDate`
* `latest_item_pubdate`: `YYYY-MM-DD` of latest item `pubDate`

For each post in a feed history4feed stores the following in the database;

* `id`: UUID of items generated by history4feed
* `feed_id`: feed id this item belongs too
* `title`: found in the `<item>` element of feed output
* `description`: found in the `<item>` element of feed output
* `link`: found in the `<item>` element of feed output
* `pubDate`: found in the `<item>` element of feed output
* `author`: found in the `<item>` element of feed output
* `category`: found in the `<item>` element of feed output

For each job run history4feed stores the following in the database;

* `id`: UUID of job
* `feed_id`: feed id the job belongs too
* `run_datetime`: time job was executed
* `earliest_item_requested`: shows the earliest time for posts requested. Useful for when jobs are run to see if the time range it runs across is expected
* `latest_item_requested`: shows the latest time for posts requested
* `state`: either `fail`, `success`, `pending`, `running`
* `info`: contains a useful summary of the job (e.g. number of posts retrieved, errors logged)

## API

### Authentication

Requests will require not authentication. This tool as designed to be run locally only.

### Schema

To make it easy for users to get up and running, we should build the API against the OpenAPI v3 spec (https://spec.openapis.org/oas/v3.1.0). We can then use Swagger (https://swagger.io/resources/open-api/) to automatically deliver a lightweight view to allow users to interact with the API in the browser.

### Pagination

We should add an `.env` variable that allows user to set max record returned per page.

All paginated responses should contain the header;

```
{
  "page_number": <NUMBER>,
  "page_size": <SET IN ENV>,
  "page_results_count": <COUNT OF RESULTS ON PAGE>,
  "total_results_count": <COUNT OF RESULTS ON ALL PAGES>,
```

### Endpoints

#### Feeds

##### POST Create a Feed

```shell
POST <HOST>/api/v1/feeds/
```

Body:

```json
{
  "url": "string"
}
```

Use this endpoint to create to a new feed.

The url value used should be a valid RSS or ATOM feed URL. For example

* good = https://www.bellingcat.com/feed/
* bad = https://www.bellingcat.com/

The server will validate that the document url resolved to is valid ATOM/RSS. If it is not valid, the Feed will not be created and an error returned.

If a feed `url` already exists in the database, that record will be returned (vs. adding a new feed).

200 new entry

```json
{
    "feeds": [
        {
        	"id": "<FEED ID>",
            "datetime_added": "<DATETIME ADDED>",
            "job_id": "<JOB ID RELATED TO FETCHING POSTS>",
            "state": "PENDING"
        }
    ]
}
```

Response paginated? FALSE

This will immediate trigger a job to get posts from NOW until the earliest post time defined in the `.env` file.

200 existing entry

```json
{
    "feeds": [
        {
            "id": "<FEED.ID>",
            "title": "<FEED.TITLE>",
            "description": "<FEED.DESCRIPTION>",
            "url": "<FEED.URL>",
            "earliest_item_pubdate": "<EARLIEST PUBDATE FOR ITEMS IN FEED>",
            "latest_item_pubdate": "<LATEST PUBDATE FOR ITEMS IN FEED>",
            "count_of_posts": "<COUNT OF ITEMS THAT BELONG TO FEED>",
            "datetime_added": "<DATETIME ADDED>"
        }
    ]
}
```

Response paginated? FALSE

##### DELETE a Feed

```shell
DELETE <HOST>/api/v1/feeds/:feed_id
```

Using the ID of a feed (obtained from GET Feeds) a user can delete a feed.

This will also DELETE all data held in the database for the feed.

200 delete entry

```json
{
    "feeds": [
        {
        	"id": "<FEED ID>",
        	"state": "DELETED"
        }
    ]
}
```

Following a successful delete, if a user tries to retrieve this feed ID, it will result in a 404.

##### POST Update a Feed

```shell
POST <HOST>/api/v1/feeds/:feed_id
```

Will immediately trigger a job to get the posts between latest_item_pubdate for feed and time request was made.

```json
{
    "feeds": [
        {
            "id": "<FEED ID>",
            "datetime_added": "<DATETIME ADDED>",
            "job_id": "<JOB ID RELATED TO FETCHING POSTS>",
            "state": "PENDING"
        }
    ]
}
```

Note, items in the remote feedd are added over time, a feed can be identified by a unique `link` and `pubDate`.

If the item has a unique `link` and `pubDate` (not found in the database) it is considered new, and should be added.

It is possible items in a feed are updated (and thus reappear in a later feed update request), in such cases a `link` and `pubDate` for a item in a feed will already match one already indexed in the database. If this happens, the latest copy of the post replaces the previous content for that item.

##### GET Feeds

Get information about feeds in the system.

```shell
GET <HOST>/api/v1/feeds/
```

Use this endpoint to get a list of all the feeds you are currently subscribed to.

This endpoint is usually used to get the id of feed you want to get blog post data for in a follow up request to the GET Feed Posts endpoints or to get the status of a job related to the Feed in a follow up request to the GET Job endpoint. If you already know the id of the Feed already, you can use the GET Feeds by ID endpoint.

URL parameters:

* title: Allows the results to be filtered on the Feeds title. Is a wildcard search.
    * default: none
    * required: false
* description Allows the results to be filtered on the Feeds based on description. Is a wildcard search.
    * default: none
    * required: false
* url: Allows results to be filtered on a the Feeds URL. Is a wildcard search.
* state: either `PENDING` or `ACTIVE`
    * default: none
    * required: false
* earliest_item_pubdate_max: Filter the results based on earliest_item_pubdate_max in format YYYY-MM-DD.
    * default: none
    * required: false
* earliest_item_pubdate_min: Filter the results based on earliest_item_pubdate_min in format YYYY-MM-DD.
    * default: none
    * required: false
* latest_item_pubdate_max: Filter the results based on latest_item_pubdate_max in format YYYY-MM-DD.
    * default: none
    * required: false
* latest_item_pubdate_min: Filter the results based on latest_item_pubdate_min in format YYYY-MM-DD.
    * default: none
    * required: false
* page:
    * default: 1
* sort: 
	* title_ascending
	* title_descending
	* url_ascending
	* url_descending
	* count_of_posts_ascending
	* count_of_posts_descending
	* earliest_item_pubdate_ascending
	* earliest_item_pubdate_descending
	* latest_item_pubdate_ascending
	* latest_item_pubdate_descending
	* datetime_added_ascending
	* datetime_added_descending (default)

200 get feeds

```json
{
    "feeds": [
        {
            "id": "<FEED.ID>",
            "title": "<FEED.TITLE>",
            "description": "<FEED.DESCRIPTION>",
            "url": "<FEED.URL>",
            "earliest_item_pubdate": "<EARLIEST PUBDATE FOR ITEMS IN FEED>",
            "latest_item_pubdate": "<LATEST PUBDATE FOR ITEMS IN FEED>",
            "count_of_posts": "<COUNT OF ITEMS THAT BELONG TO FEED>",
            "datetime_added": "<DATETIME ADDED>"
        },
        {
            "id": "<FEED.ID>",
            "title": "<FEED.TITLE>",
            "description": "<FEED.DESCRIPTION>",
            "url": "<FEED.URL>",
            "earliest_item_pubdate": "<EARLIEST PUBDATE FOR ITEMS IN FEED>",
            "latest_item_pubdate": "<LATEST PUBDATE FOR ITEMS IN FEED>",
            "count_of_posts": "<COUNT OF ITEMS THAT BELONG TO FEED>",
            "datetime_added": "<DATETIME ADDED>"
        }
    ]
}
```

Response paginated? TRUE

##### GET Feed by ID

Get information about a specific feed

```shell
GET <HOST>/api/v1/feeds/:feed_id
```

200 get feed

```json
{
    "feeds": [
        {
            "id": "<FEED.ID>",
            "title": "<FEED.TITLE>",
            "description": "<FEED.DESCRIPTION>",
            "url": "<FEED.URL>",
            "earliest_item_pubdate": "<EARLIEST PUBDATE FOR ITEMS IN FEED>",
            "latest_item_pubdate": "<LATEST PUBDATE FOR ITEMS IN FEED>",
            "count_of_posts": "<COUNT OF ITEMS THAT BELONG TO FEED>",
            "datetime_added": "<DATETIME ADDED>"
        }
    ]
}
```

Response paginated? FALSE

##### GET Posts for a feed (JSON)

```shell
GET HOST/api/VERSION/feeds/:feed_id/posts/json
```

Accepts URL parameters;

* `title`: allows results to be filtered on title. Value entered is wildcard.
    * default: none
    * required: false
* `description`: allows results to be filtered on description. Value entered is wildcard.
    * default: none
    * required: false
* `pubdate_min`: the earliest post date to be returned in format YYYY-MM-DD. If `pubdate_max` this value must be lower
    * default: none
    * required: false
* `pubdate_max`: the latest post date to be returned in format YYYY-MM-DD.. If `pubdate_min` this value must be lower
    * default: none
    * required: false
* `page`
    * default is 0
* `sort`:
	* pubdate_descending (default)
	* pubdate_ascending
	* title_descending
	* title_ascending

Will return a response in the following structure.

```json
{
    "posts": [
        {
            "id": "<value>",
            "datetime_added": "<value>",
            "datetime_updated": "<value>",
            "title": "<value>",
            "description": "<value>",
            "link": "<value>",
            "pubDate": "<value>",
            "author": "<value>",
            "category": [
                "<value>"
            ]
        },
        {
            "id": "<value>",
            "datetime_added": "<value>",
            "datetime_updated": "<value>",
            "title": "<value>",
            "description": "<value>",
            "link": "<value>",
            "pubDate": "<value>",
            "author": "<value>",
            "category": [
                "<value>"
            ]
        }
    ]
}
```

Response paginated? TRUE

##### GET a Post for a feed

```shell
GET HOST/api/VERSION/feeds/:feed_id/posts/json/:post_id
```

Will return a response in the following structure.

```json
{
    "posts": [
        {
            "id": "<value>",
            "datetime_added": "<value>",
            "datetime_updated": "<value>",
            "title": "<value>",
            "description": "<value>",
            "link": "<value>",
            "pubDate": "<value>",
            "author": "<value>",
            "category": [
                "<value>"
            ]
        }
    ]
}
```

Response paginated? FALSE

##### Get Posts for a feed (XML)

There is a special Get Posts endpoints designed for RSS readers to connect to. This is for 2 reasons:

1. These readers don't typically allow user to modify request headers, so all the information needs to be passed in URL parameters.
2. It also delivers the payload in RSS XML only. This is because feed readers are dumb, and only understand RSS XML structure.

```shell
GET HOST/api/VERSION/feeds/:feed_id/posts/xml
```

Accepts URL parameters;

* `pubdate_min`: the earliest post date to be returned in format YYYY-MM-DD. If `pubdate_max` this value must be lower
    * default: none
    * required: false
* `pubdate_max`: the latest post date to be returned in format YYYY-MM-DD.. If `pubdate_min` this value must be lower
    * default: none
    * required: false

This will print a full RSS file for all items in the feed (that match the criteria) as follows;

```xml
<?xml version="1.0" encoding="UTF-8" ?>
    <rss version="2.0">
        <channel>
            <title>FEED.TITLE</title>
            <description>FEED.DESCRIPTION</description>
            <link>FEED.URL</link>
            <lastBuildDate>FEED.latest_item_pubdate</lastBuildDate>
            <generator>https://www.fulltextfeed.com</generator>
            <item>
                <title>ITEM.TITLE</title>
                <description>ITEM.DESCRIPTION</description>
                <link>ITEM.LINK</link>
                <pubDate>ITEM.PUBDATE</pubDate>
                <author>ITEM.AUTHOR</author>
                <category>ITEM.CATERGORY [N]</category>
                <category>ITEM.CATERGORY [N]</category>
            </item>
            <item>
                <title>ITEM.TITLE</title>
                <description>ITEM.DESCRIPTION</description>
                <link>ITEM.LINK</link>
                <pubDate>ITEM.PUBDATE</pubDate>
                <author>ITEM.AUTHOR</author>
                <category>ITEM.CATERGORY [N]</category>
                <category>ITEM.CATERGORY [N]</category>
            </item>
        </channel>
    </rss>
</xml>
```

Response paginated? FALSE

#### Jobs

##### GET Get jobs

Jobs allow users to track the status of the request to get posts for feeds they've added to the database.

Jobs for daily updates for each feed are not shown to a user. This only shows jobs triggering a backfill for URL triggered by that user.

```shell
GET HOST/api/VERSION/jobs
```

Accepts URL parameters;

* `feed_id`: allows results to be filtered by feed ID
    * default: none
    * required: false
* `state`: either `fail`, `success`, `pending`, `running`
    * default: all
    * required: false
* `page`
    * default: 0
* `sort`
    * run_datetime_descending (default)
    * run_datetime_ascending
    * state_ascending
    * state_descending

200 response

```json
{
    "jobs": [
        {
            "id": "<value>",
            "state": "<value>",
            "run_datetime": "<value>",
            "earliest_item_requested": "<value>",
            "latest_item_requested": "<value>",
            "feed_id": "<value>",
            "info": "<value>"
        },
        {
            "id": "<value>",
            "state": "<value>",
            "run_datetime": "<value>",
            "earliest_item_requested": "<value>",
            "latest_item_requested": "<value>",
            "feed_id": "<value>",
            "info": "<value>"
        }
    ]
}
```

Response paginated? TRUE

##### Get Job

```shell
GET HOST/api/VERSION/jobs/:job_id
```

200 response

```json
{
    "jobs": [
        {
            "id": "<value>",
            "state": "<value>",
            "run_datetime": "<value>",
            "earliest_item_requested": "<value>",
            "latest_item_requested": "<value>",
            "feed_id": "<value>",
            "info": "<value>"
        }
    ]
}
```

### Errors

Bad parameters / bad request format;

```json
{
	"message": " The server did not understand the request",
	"code": 400
}
```

Endpoint / feed / job does not exist

```json
{
	"message": " The server cannot find the resource you requested",
	"code": 404
}
```

Not RSS / ATOM format (add new feed)

```json
{
	"message": " The URL entered is not a valid RSS or ATOM feed",
	"code": 406
}
```